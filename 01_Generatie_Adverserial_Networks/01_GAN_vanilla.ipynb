{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # converts to float AND divides by 255 (normalize).\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # scale to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load Fashion-MNIST dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, transform=transform)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images and labels from loader\n",
    "numbers, labels = next(iter(train_loader))\n",
    "\n",
    "# visualize one image\n",
    "images = numbers.numpy()\n",
    "# get one image from the batch\n",
    "img = np.squeeze(images[0])\n",
    "fig = plt.figure(figsize = (1,1)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize a batch of images\n",
    "grid = torchvision.utils.make_grid(numbers, nrow=8, padding=0, scale_each=True)\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "plt.imshow(grid.cpu().permute(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Model:  A GAN is comprised of two adversarial networks, a discriminator and a generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator : The discriminator network is going to be a pretty typical linear classifier. To make this network a universal function approximator, we'll need at least one hidden layer, and these hidden layers should have a Leaky ReLu activation function applied to their outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.disciminator = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim*4),\n",
    "            nn.ReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim*4, hidden_dim*2),\n",
    "            nn.ReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # flatten image\n",
    "        out = self.disciminator(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator : The generator network will be almost exactly the same as the discriminator network, except that we're applying a tanh activation function to our output layer. Tanh scales the output to be between -1 and 1, instead of 0 and 1. these outputs to be comparable to the real input pixel values, which are read in as normalized values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim),\n",
    "            nn.ReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim*2),\n",
    "            nn.ReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim*4),\n",
    "            nn.ReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim*4, output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.generator(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator hyperparams\n",
    "input_size    = 784   # Size of input image to discriminator (28*28)\n",
    "d_hidden_size = 32    # Size of last hidden layer in the discriminator\n",
    "d_output_size = 1     # Size of discriminator output (real or fake)\n",
    "\n",
    "# Generator hyperparams\n",
    "z_size        = 100  # Size of latent vector to give to generator\n",
    "g_hidden_size = 32   # Size of first hidden layer in the generator\n",
    "g_output_size = 784  # Size of discriminator output (generated image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build models and move to device\n",
    "D = Discriminator(input_size, d_hidden_size, d_output_size)\n",
    "G = Generator(z_size, g_hidden_size, g_output_size)\n",
    "\n",
    "# Send models to device\n",
    "D = D.to(device)\n",
    "G = G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=0.0001)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For generating latent noise\n",
    "def generate_noise(batch_size, latent_size):\n",
    "    return torch.randn(batch_size, latent_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 150\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for real_images, _ in train_loader:\n",
    "        real_images = real_images.view(-1, input_size).to(device)\n",
    "        batch_size_curr = real_images.size(0)\n",
    "\n",
    "        # Labels for real and fake images\n",
    "        real_labels = torch.ones(batch_size_curr, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size_curr, 1).to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        outputs = D(real_images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "\n",
    "        noise = generate_noise(batch_size_curr, z_size)\n",
    "        fake_images = G(noise)\n",
    "        outputs = D(fake_images.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Train Generator\n",
    "        noise = generate_noise(batch_size_curr, z_size)\n",
    "        fake_images = G(noise)\n",
    "        outputs = D(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)  # We want the fake images to be classified as real\n",
    "\n",
    "        G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
    "\n",
    "    # Generate and show fake images every 10 epochs\n",
    "    if (epoch+1) % 30 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake_images = fake_images.reshape(-1, 1, 28, 28)\n",
    "            fake_images = fake_images[:16]\n",
    "            grid = torchvision.utils.make_grid(fake_images, nrow=4, normalize=True)\n",
    "            plt.figure(figsize=(3,3))\n",
    "            plt.imshow(grid.permute(1,2,0).cpu())\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Fake images at epoch {epoch+1}')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
